# Results
```{r, message=FALSE, warning=FALSE}
library(jsonlite)
library(tidyverse)
library(dplyr)
library(knitr)
library(tokenizers)
library(syuzhet)
library(ggplot2)
library(tm)
library(tidytext)
library(wordcloud)
library(lubridate)
library(scales)
library(usmap)
library(emo) 
library(gt)
```

```{r}
#Read in the dataset
df <- read.csv("data/EM_df.csv",encoding="latin1")
df <- df %>%
  select(-c(X,geo.type,geo.coordinates)) 

```

```{r}
#Reformat timestamp
df <- df %>%
  mutate(created_at = as.character(strptime(created_at,"%a %b %d %H:%M:%S %z %Y", tz = "EST"))) %>%
  mutate(date = as.Date(created_at))

```

```{r}
#Calculate the duration of collecting period for each day
df_1028 <- df %>%
  filter(date=="2021-10-28")

dt1028 <- difftime(df_1028$created_at[nrow(df_1028)], df_1028$created_at[1], unit="hours")

df_1029 <- df %>%
  filter(date=="2021-10-29")

dt1029 <- difftime(df_1029$created_at[nrow(df_1029)], df_1029$created_at[1], unit="hours")

df_1030 <- df %>%
  filter(date=="2021-10-30")

dt1030 <- difftime(df_1030$created_at[nrow(df_1030)], df_1030$created_at[1], unit="hours")

df_1031 <- df %>%
  filter(date=="2021-10-31")

dt1031 <- difftime(df_1031$created_at[nrow(df_1031)], df_1031$created_at[1], unit="hours")

df_1101 <- df %>%
  filter(date=="2021-11-01")

dt1101 <- difftime(df_1101$created_at[nrow(df_1101)], df_1101$created_at[1], unit="hours")

df_1102 <- df %>%
  filter(date=="2021-11-02")

dt1102 <- difftime(df_1102$created_at[nrow(df_1102)], df_1102$created_at[1], unit="hours")

df_1103 <- df %>%
  filter(date=="2021-11-03")

dt1103 <- difftime(df_1103$created_at[nrow(df_1103)], df_1103$created_at[1], unit="hours")

tn <- c(dt1028,dt1029,dt1030,dt1031,dt1101,dt1102,dt1103)
tn <- as.numeric(tn)
```

## Elon Musk

Elon Musk is very active on twitter and anything he tweets can be very influential and brings a lot of controversies. For example, his tweet about the crypto-currency "dogecoin" caused "dogecoin" price to spike. Since Twitter users have many discussions surrounding him, our analysis aims to visualize those discussions. 

The period of which we collected our data was very interesting. It was shortly after Tesla flied in stock market and Elon Musk became the richest man in the world. He was also asked by the United Nation to donate 4% of his growing wealth to solve a hunger crisis. Just shortly after that, on Nov. 1st, he posted a Chinese poem "七步诗" titled as "Humankind", which seems to be describing dogecoin and shiba inu coin.


![](data/poem.png)

## Volume of tweets

We first carried out analysis on the number of tweets that we collected each day. Due to some technical issues, the durations we collected tweets each day are different. They were about 10-12 hours each day, with one excepetion on Oct 29. On that day, we collected tweets for about 5.5 hours. In order to present a consistent results through the period, we standardize the tweets by dividing the total collected hour and multiplying by 24. The following graph presents expected number of tweets each day.

```{r}
time_df <- df %>% 
  group_by(date) %>%
  count() %>%
  filter(is.na(date) == FALSE) %>%
  add_column(period=tn) %>%
  mutate(standardized= (n*24)/period) %>%
  ungroup

ggplot(time_df, aes(date,standardized)) +
    geom_line(color="lightblue3") + 
    scale_x_date(date_breaks="1 day") +
    ggtitle("Expected number of tweets each day") +
    xlab("Date") +
    ylab("Standardized number of tweets") +
    theme_bw()
```

From the graph, we see that the volume each day can be as low as 70 thousands and as high as 250 thousands. There were two peaks on Oct. 29th and Nov 1st. For the first peak, we corresponded it to the drastic increase in Tesla's stock price. For the second peak, we related to the conversation between an United Nation offical and Elon Musk. We notice from below that this conversation has 337.5 thousand likes, showing its tremendous volume of attention. Observing these patterns, we conclude that controversial events associated with Elon Musk will cause an increase in discussion on Twitter.  

<center>
![](data/UN_EM.png){width=50%}
</center>

## Geological Distribution

Even though we have limited data on geological information of users, we still want to make use of them to explore some patterns.
In total we have 5293 tweets that contain a user geological information. The location is not limited to the United States, and we conducted filtering for each states.

```{r}
geo_df <- df %>%
  filter(!is.na(location))
```

```{r}
state_list <- c("Alabama","AL","Alaska","AK",	"Arizona","AZ","Arkansas","AR","California","CA","Colorado","CO",
"Connecticut","CT","Delaware","DE","Florida","FL","Georgia","GA","Hawaii","HI","Idaho","ID","Illinois","IL",
"Indiana","IN","Iowa","IA","Kansas","KS","Kentucky","KY","Louisiana","LA",	"Maine","ME","Maryland","MD",	
"Massachusetts","MA",	"Michigan","MI",	"Minnesota","MN",	"Mississippi","MS",	"Missouri","MO","Montana","MT",	
"Nebraska","NE",	"Nevada","NV","New Hampshire","NH","New Jersey","NJ","New Mexico",	"NM","New York",	"NY",
"North Carolina",	"NC","North Dakota",	"ND","Ohio", "OH",	"Oklahoma",	"OK",	"Oregon",	"OR",	"Pennsylvania",	"PA",	
"Rhode Island",	"RI","South Carolina",	"SC",	"South Dakota",	"SD","Tennessee",	"TN",	"Texas","TX","Utah","UT",
"Vermont","VT","Virginia","VA","Washington","WA","West Virginia","WV","Wisconsin","WI","Wyoming","WY")
```

```{r}
for (i in 1:nrow(geo_df)){
  loc <- geo_df$location[i]
  loc_split1 <- str_split(loc,", ")[[1]][1]
  loc_split2 <- str_split(loc,", ")[[1]][2]
  
  if(loc_split2 %in% state_list == TRUE){
    geo_df$location[i] = loc_split2
  } else {
    geo_df$location[i] = NA
  }
}
```

```{r}
geo_df_r <- geo_df %>%
  filter(!is.na(location)) %>%
  group_by(location) %>%
  count()

colnames(geo_df_r)[1] <- "state"
```

```{r}
plot_usmap(data=geo_df_r,values="n") + 
  scale_fill_continuous(low = "white", high = "deepskyblue", name = "Tweet posted") +
  labs(title = "United States", subtitle = "Number of tweets posted by states") +
  theme(panel.background=element_blank(),legend.position = "right")
    
```

From the state graph, we can see that users mainly locate in four states. They are California, Texas, Florida, and New York, with 503, 336, 248, and 187 users respectively. Even though we have a fairly small sample, it still seems that users in more economically developed state tend to discuss more related to Elon Musk.

## Tweet Contents

Now, our analysis dive into the tweet-level. We are concerned with the contents of the tweets. Even though it is impossible for us to examine tweet by tweet, we use powerful Natural Language Processing techniques to explore patterns. 

### Word Frequency

We first look at some most frequent words that appear across tweets. By inspecting the word frequency histogram and the word cloud, we can have some insight about what people were discussing inside these tweets.

```{r}
# fix sentiment column
for (i in 1:length(df$sentiment)){
  if(!(df$sentiment[i] %in% c("neutral","negative","positive"))){
    if(df$sentiment[i]>0){
      df$sentiment[i]="positive"
    }
    if(df$sentiment[i]==0){
      df$sentiment[i]="neutral"
    }
    if(df$sentiment[i]<0){
      df$sentiment[i]="negative"
    }
  }
}
```

```{r}
# create corpus
df$cleaned_text = tolower(df$cleaned_text)
text <- removeWords(df$cleaned_text, words = stopwords(kind = "en"))
text <- tibble(txt=text)
tweets_words <-  text %>%
 unnest_tokens(word, txt)
words <- tweets_words %>% count(word, sort=TRUE)
```

```{r}
#clean words corpus

#separate words and emoji
emoji <- words %>% subset(substr(word,1,3)=="000")
words <- words %>% subset(!(substr(word,1,3)=="000"))

#remove word meaningless or search words
remove_words <- c("u", "elonmusk","tesla","fe0f","279c","elon","musk","s")
words <- words %>% subset(!(word %in% remove_words))
```


```{r,fig.width=12, fig.height=8}
#word frequency histogram
words %>%
  top_n(15) %>%
  ggplot()+
    geom_bar(aes(x=reorder(word,n),y=n),stat="identity",fill="lightblue")+
    ggtitle("Top 15 words of all tweets") +
    xlab("words")+
    ylab("Occurence") +
    coord_flip() +
    theme_bw() +
    theme(axis.text=element_text(size=12))

```

We can see that in the frequency graph that most of the words are related to crypto-currency. The word "will"  and "can" have the most frequency. In relating to the topic of crypto-currency, we hypothesis the pattern to be Twitter users love to envision the future of crypto-currency and use "will" and "can" to express their expectations. 

```{r}
#word cloud
wordcloud(words = words$word, freq = words$n, min.freq = 1,max.words=100, random.order=FALSE, rot.per=0.35, colors=brewer.pal(5, "Greens"))
```

The word cloud presents more words of high frequency. The words "doge", "billym2k" and "dogecoin" are in the top 15 words list, and they are describing the same object-dogecoin. Dogecoin is a cryptocurrency that are created as a "joke" to make fun of the fact that everyone can copy bitcoin's open source code and publish a new cryptocurrency. Elon Musk is a big supporter for dogecoin, calling it "people's crypto." It is also unsurprising that these the words like "bitcoin", "binance" and "crypto" are frequent in the tweets since Elon Musk is a big fan of bitcoin. 

The username "DrEliDavid" and the word "hunger" also appeared a lot. The story began in Oct. 30th when Dr. Eli David shared an image of a CNN Business article with the headline: “2% of Elon Musk’s wealth could solve world hunger, says director of UN food scarcity organization.” Elon Musk tweeted that he would sell Tesla stock if WFP can prove how his 6 billion dollar can solve world hunger. There were lots of online dialogue between the two sides since Musk’s request for spending to be published. We can also see "spaceX" and "mars" as referring to his project of sending human to Mars. However,we can clearly these topics have less popularity. 

Another interesting finding is the use of emojis. The following is a table of top 5 emojis frequency.

```{r}
# emoji count
top_emoji <- emoji%>%top_n(5)
#change unicode to emoji
top_emoji$word[1] <- emo::ji("rocket")
top_emoji$word[2] <- emo::ji("fire")
top_emoji$word[3] <- emo::ji("finger")
top_emoji$word[4] <- emo::ji("gem")
top_emoji$word[5] <- emo::ji("smile")
colnames(top_emoji) <- c("emoji","count")
top_emoji %>% gt() #emoji appear after knitting
```
It is very interesting that "rocket" appears to be the most frequent emoji. We are unsure if it is responding to the spaceX project, or if it is expectation on the price of crypto-currceny: "To the moon `r emo::ji("rocket")`". 

### Tweet sentiment

Moving forward, we look at the sentiment of tweets and how the sentiment correlates with other features in our dataset. Previously, we have assigned a sentiment score for each tweet based on the usage of words and classify them into categories. In this section, we expand sentiment classification as follows: very positive(>1.2),positive(0.2,1.2],neutral[-0.2,0.2], negative[-1.2,-0.2), and very negative(<-1.2) in order to create more insightful observations.

```{r}
df_senti <- df %>%
  mutate(sentiment_score = as.numeric(sentiment_score)) %>%
  mutate(sentiment = case_when(
    sentiment_score > 1.2 ~ "very positive",
    sentiment_score <= 1.2 & sentiment_score > 0.2 ~ "positive",
    sentiment_score <= 0.2 & sentiment_score >= -0.2 ~ "neutral",
    sentiment_score >= -1.2 & sentiment_score < -0.2 ~ "negative",
    sentiment_score < -1.2  ~ "very negative"))
```

```{r}
l = c("very negative","negative","neutral","positive","very positive")

df_senti %>% 
  filter(!is.na(sentiment)) %>%
  group_by(sentiment) %>%
  count() %>%
  mutate(perc = n/nrow(df_senti)) %>%
  ggplot(aes(x=fct_relevel(sentiment,l),y=perc)) +
    geom_bar(fill="lightblue",stat="identity") +
    ggtitle("Sentiment distribution") +
    xlab("Sentiment Categories") +
    ylab("Proportion") + 
    theme_bw()
```

From the graph, we can see that the overall sentiment is very positive. Over 85% of the tweets are either neutral or positive. Neutral and positive tweets have similar percentage of 33%. Elon Musk presents to be very unorthdodox on Twitter, and other users seems to identify with his style.

We then explore some correlations between sentiment scores and other features. Firstly we look at if the length of tweets would have some impacts on the sentiment.

```{r}
#Find tweet length
df_length <- df_senti %>%
  mutate(tweet_length = nchar(original_text)) %>%
  group_by(tweet_length) %>%
  summarise(across(sentiment_score,mean)) %>%
  filter(tweet_length < 1000)


```

```{r}
ggplot(data=df_length,aes(x=tweet_length,y=sentiment_score)) +
    geom_line(color="lightblue3") + 
    ggtitle("Correlation between tweet length and average sentiment score") +
    xlab("tweet length") +
    ylab("average sentiment score") +
    theme_bw()
```

We can see a clear trend of increasing average sentiment as the tweet length grows. At around tweet length of 400, we see a pattern of slight decrease in average sentiment towards 0. We conclude that users are more likely to express positive emotions regarding Elon Musk as the tweet length increases. However, for tweets that are excessively long, the emotion tends to be more neutral and even negative.

We then try to explore if there is a relationship between sentiment and number of followers.

```{r}
df_fol <- df_senti %>%
  mutate(user_follower_count = log(user_follower_count)) %>%
  group_by(user_follower_count) %>%
  summarise(across(sentiment_score,mean)) %>%
  filter(!user_follower_count=="-Inf")

```

```{r}
ggplot(data=df_fol,aes(x=user_follower_count,y=sentiment_score)) +
    geom_point(color="lightblue3",alpha=0.4) + 
    ggtitle("Correlation between number of followers and average sentiment score") +
    xlab("log(Number of followers)") +
    ylab("average sentiment score") +
    theme_bw()
```

We can see that it is a fan shaped graph. The average sentiment score for average Twitter user is generally flat and does not have much fluctuation. However, for people who are more influential (more followers), their attitudes seems to vary. We conclude that while average Twitter users are generally favorable of Elon Musk, more influential users can have varying opinions towards Elon Musk.

### Monitoring Topics

After the exploration of words and sentiments, we want to further find out how those high frequencey vocabulary are related. To to this, we apply topic modeling(LDA). LDA is an unsupervised generative probabilistic model which, typically given the number of topics, allocates each word in a document to a specific topic. [**Click here to see an interactive LDA result in which we select 6 topics**](EM_lda6.html). There is a detail description on how to read the graph in the page.

From the result, we roughly extract two topics. The first and second topic in the graph overlap. Based on the keywords "tesla", "world", "hunger",and "stock", we think this is a general topic regarding the spike of Tesla stock and the conversation between Elon Musk and United Nation offical. The third, fourth, and fifth topics are close in distance. We see various crypto-currency keywords like "bitcoin","binance","eth", etc.. Those topics are discussions focusing on crypto-currencies. For the sixth topic, even though it is far away from other topics, we still think it talks about crpypto currencies. We see keywords "buy", "hold", and "kishu". Therefore, we capture two topics corresponding to the content of Elon Musk's tweets. The first topic about Tesla and United Nation's proposal constitute about 53% of all the discussions. The second topic about crypto-currency makes up about 47% all the discussion. 



